{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run distributed:\n",
    "\n",
    "```\n",
    "make\n",
    "```\n",
    "\n",
    "```\n",
    "CUDA_VISIBLE_DEVICES=3,4,5,1,2,0 python -m torch.distributed.launch --master_port 1235 --nproc_per_node=6 02_train.py --epochs 30 --bs 96 --fp16 to_fp16 --trf_heads 4 --mixup False --chunk_size 500 --trf_dim 512 --loss ce --n_chunks 1 --fit fit_flat_cos --fit_kwargs pct_start=0.5 div_final=100 --tfixup True --pad r --valid_pct 0.025 --trf_act gelu --opt ranger_lamb --lr 3e-3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics       import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.distributed  import *\n",
    "from fastai.tabular.all  import *\n",
    "from fastai.test_utils   import *\n",
    "\n",
    "import ast\n",
    "import enum\n",
    "import gc\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import enum\n",
    "\n",
    "from collections import defaultdict\n",
    "from fastcore.script import *\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from pytorch_block_sparse.util import ModelPatcher\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.distributions.beta import Beta\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_d = Path('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@call_parse\n",
    "def main(\n",
    "    model:         Param(\"Name\", str) = '210105',\n",
    "    data:          Param(\"Data version\", str) = '210101b',\n",
    "    load:          Param(\"Load from\", str) = None,\n",
    "    validate:      Param(\"\", action='store_true') = False,\n",
    "    chunk_size:    Param(\"Chunk size\", int) = 500,\n",
    "    n_chunks:      Param(\"Number of chunks\", int) = 1,\n",
    "    #chunk_size:    Param(\"Chunk size\", int) = 50,  \n",
    "    #n_chunks:      Param(\"Number of chunks\", int) = 10,    \n",
    "    #bs:            Param(\"BS\", int) = 96,\n",
    "    bs:            Param(\"BS\", int) = 48,    #2 works, 96 doesn't\n",
    "    workers:       Param(\"\", int) = 8,\n",
    "    valid_pct:     Param(\"Validation set\", float) = 0.025,\n",
    "    trf_dim:       Param(\"\", int) = 512,\n",
    "    trf_enc:       Param(\"\", int) = 4,\n",
    "    trf_dec:       Param(\"\", int) = 4,\n",
    "    trf_heads:     Param(\"\", int) = 4,\n",
    "    trf_do:        Param(\"\", float) = 0.1,\n",
    "    trf_act:       Param(\"\", str) = 'gelu',\n",
    "    lr:            Param(\"\", float) = 3e-3,\n",
    "    clip:          Param(\"\", float) = 0.,\n",
    "    \n",
    "    moms:          Param(\"Moms for fit_one_cycle\", float, nargs='+') = (0.95,0.85,0.95),\n",
    "    epochs:        Param(\"Epochs\", int) = 5, #Original was 30,\n",
    "    tfixup:        Param(\"Use T-Fixup init\", ast.literal_eval) = True,\n",
    "    mixup:         Param(\"Use mixup\", ast.literal_eval) = False,\n",
    "    opt:           Param(\"Optimizer\", str) = 'ranger_lamb',\n",
    "    opt_kwargs:    Param(\"Optional args for opt, eg. eps=1e-4\", str, nargs='+') = {},\n",
    "    fit:           Param(\"fit or fit_one_cycle\", str) = 'fit_flat_cos',\n",
    "    fit_kwargs:    Param(\"Optional args for fit,eg pct_start=0.1\", str, nargs='+') = ['pct_start=0.5', 'div_final=100.'],\n",
    "    fp16:          Param(\"fp16 method: to_fp16, to_native_fp16, none\", str) = 'to_fp16',\n",
    "    \n",
    "    loss:          Param(\"Loss\", str) = 'ce',\n",
    "    \n",
    "    wua:           Param(\"Weight of user_answer term in the loss\", float) = 0.,\n",
    "    pad:           Param (\"Pad left of right (l|r)\",str,choices=['l','r'])='r',\n",
    "\n",
    "    local_rank:    Param(\"--local_rank\", int) = None,\n",
    "): \n",
    "    if opt_kwargs: opt_kwargs = {s.split('=')[0]:float(s.split('=')[1]) for s in opt_kwargs}\n",
    "    if fit_kwargs: fit_kwargs = {s.split('=')[0]:float(s.split('=')[1]) for s in fit_kwargs}\n",
    "    print(locals())\n",
    "    globals().update({ 'H' : AttrDict(locals())})\n",
    "_H = AttrDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': '210105', 'data': '210101b', 'load': None, 'validate': False, 'chunk_size': 500, 'n_chunks': 1, 'bs': 48, 'workers': 8, 'valid_pct': 0.025, 'trf_dim': 512, 'trf_enc': 4, 'trf_dec': 4, 'trf_heads': 4, 'trf_do': 0.1, 'trf_act': 'gelu', 'lr': 0.003, 'clip': 0.0, 'moms': (0.95, 0.85, 0.95), 'epochs': 5, 'tfixup': True, 'mixup': False, 'opt': 'ranger_lamb', 'opt_kwargs': {}, 'fit': 'fit_flat_cos', 'fit_kwargs': {'pct_start': 0.5, 'div_final': 100.0}, 'fp16': 'to_fp16', 'loss': 'ce', 'wua': 0.0, 'pad': 'r', 'local_rank': None}\n"
     ]
    }
   ],
   "source": [
    "#noexport\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = torch.cuda.device_count() if H.local_rank is None else 1\n",
    "if H.local_rank is not None:\n",
    "    torch.cuda.set_device(H.local_rank)\n",
    "    torch.distributed.init_process_group(backend='nccl', init_method='env://')\n",
    "    print(f\"DISTRIBUTED: {H.local_rank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read df and meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO detect if meta exists and don't load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(in_d / f'meta_v{H.data}.pkl', 'rb') as f:\n",
    "    meta = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "QCols = enum.IntEnum('QCols', meta.qcols, start=0)\n",
    "LCols = enum.IntEnum('LCols', meta.lcols, start=0)\n",
    "Cats  = enum.IntEnum('Cats',  meta.cat_names, start=0)\n",
    "Conts = enum.IntEnum('Conts', meta.cont_names, start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "with open(in_d / f'data_v{H.data}.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO detect if data exists and don't load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data.attempt_num_coo\n",
    "del data.attempts_correct_coo\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = meta.icats['answered_correctly'],meta.icats['user_answer']\n",
    "y_d = {}\n",
    "for k, v in data.cat_d.items():\n",
    "    y_d[k] = np.column_stack((lut[0][v[:,Cats.answered_correctly] - 1],lut[1][v[:,Cats.user_answer] - 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chop sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop_sequence(d):\n",
    "    nv = defaultdict(dict)\n",
    "    for k, v in d.items():\n",
    "        i = 0\n",
    "        while i*H.chunk_size < len(v):\n",
    "            nv[k][i] = v[i*H.chunk_size:(i+1)*H.chunk_size]\n",
    "            i += 1\n",
    "    return nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_d  = chop_sequence(data.cat_d)\n",
    "cont_d = chop_sequence(data.cont_d)\n",
    "tags_d = chop_sequence(data.tags_d)\n",
    "tagw_d = chop_sequence(data.tagw_d)\n",
    "y_d    = chop_sequence(y_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert np.concatenate(list(cat_d.values())).shape[0] == np.concatenate(list(data.cat_d.values())).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 393656 different users\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(data.cat_d)} different users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_keys = sorted(list(cat_d.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last H.valid_pct is valid set\n",
    "train_group_keys = group_keys[:int((1 - H.valid_pct) * len(group_keys))]\n",
    "valid_group_keys = group_keys[int((1 - H.valid_pct) * len(group_keys)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users: train=383814, valid=9842\n"
     ]
    }
   ],
   "source": [
    "print(f'users: train={len(train_group_keys)}, valid={len(valid_group_keys)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dict(d, keys):\n",
    "    return { (u, t): d[u][t] for u in keys for t in d[u].keys() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_cat =  split_dict(cat_d, train_group_keys)\n",
    "train_x_cont = split_dict(cont_d, train_group_keys)\n",
    "train_x_tags = split_dict(tags_d, train_group_keys)\n",
    "train_x_tagw = split_dict(tagw_d, train_group_keys)\n",
    "train_y =      split_dict(y_d, train_group_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_cat =  split_dict(cat_d, valid_group_keys)\n",
    "valid_x_cont = split_dict(cont_d, valid_group_keys)\n",
    "valid_x_tags = split_dict(tags_d, valid_group_keys)\n",
    "valid_x_tagw = split_dict(tagw_d, valid_group_keys)\n",
    "valid_y =      split_dict(y_d, valid_group_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqs: train=507050, valid=12914\n"
     ]
    }
   ],
   "source": [
    "print(f'seqs: train={len(train_x_cat)}, valid={len(valid_x_cat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionsDataset(Dataset):\n",
    "    def __init__(self, x_cat, x_cont, x_tags, x_tagw, y, minids=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.means = np.expand_dims(meta.means, axis=0) # ready to broadcast\n",
    "        self.stds  = np.expand_dims(meta.stds , axis=0)\n",
    "        \n",
    "        self.n_inp = 5  # number of feature (x) tensors\n",
    "        \n",
    "        self.x_cat = x_cat  # SL, XF (sequence len, feature columns) \n",
    "        self.x_cont = x_cont\n",
    "        self.x_tags = x_tags      \n",
    "        self.x_tagw = x_tagw\n",
    "        self.y = y  # SL, 1\n",
    "        \n",
    "        self.keys = list(self.x_cat.keys()) # list of group keys\n",
    "        \n",
    "        if minids:\n",
    "            self.keys = self.keys[:H.bs*2]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys) # H.bs * 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_id, time_slice = self.keys[idx]\n",
    "        win = range(max(0, time_slice - H.n_chunks + 1), time_slice + 1)\n",
    "        x_cat  = np.concatenate([ self.x_cat [(user_id, ts)] for ts in win ])\n",
    "        x_cont = np.concatenate([ self.x_cont[(user_id, ts)] for ts in win ])\n",
    "        x_tags = np.concatenate([ self.x_tags[(user_id, ts)] for ts in win ])\n",
    "        x_tagw = np.concatenate([ self.x_tagw[(user_id, ts)] for ts in win ])\n",
    "        y      = np.concatenate([ self.y     [(user_id, ts)] for ts in win ])\n",
    "        \n",
    "        pad = H.chunk_size * H.n_chunks - x_cat.shape[0]\n",
    "        \n",
    "        # Normalize x_cont\n",
    "        x_cont = (x_cont - self.means) / self.stds\n",
    "        x_cont[np.isnan(x_cont)] = 0\n",
    "        \n",
    "        padt = (0,pad) if H.pad == 'r' else (pad,0)\n",
    "        \n",
    "        x_mask = np.zeros(x_cat.shape[0], dtype=np.bool)\n",
    "        \n",
    "        x_mask = np.pad(x_mask, padt, constant_values=(True))\n",
    "        x_cat  = np.pad(x_cat , (padt, (0, 0)), constant_values=(0)).astype(np.int64)\n",
    "        x_cont = np.pad(x_cont, (padt, (0, 0)), constant_values=(0)).astype(np.float32)\n",
    "        x_tags = np.pad(x_tags, (padt, (0, 0)), constant_values=(0)).astype(np.int64)\n",
    "        x_tagw = np.pad(x_tagw, (padt, (0, 0)), constant_values=(0.)).astype(np.float32)\n",
    "        y      = np.pad(y,      (padt, (0, 0)), constant_values=(-1)).astype(np.int64)\n",
    "\n",
    "        return x_mask, x_cat, x_cont, x_tags, x_tagw, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = InteractionsDataset(train_x_cat, train_x_cont, train_x_tags, train_x_tagw, train_y)\n",
    "valid_ds = InteractionsDataset(valid_x_cat, valid_x_cont, valid_x_tags, valid_x_tagw, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mask, x_cat, x_cont, x_tags, x_tagw, y = train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507050"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_tagw[-47:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x_cat.shape == (H.chunk_size*H.n_chunks, len(meta.cat_names))\n",
    "assert x_cont.shape == (H.chunk_size*H.n_chunks, len(meta.cont_names))\n",
    "assert x_tags.shape == x_tagw.shape == (H.chunk_size*H.n_chunks, 6)\n",
    "assert y.shape == (H.chunk_size*H.n_chunks, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs=H.bs, shuffle=True, drop_last=True, num_workers=H.workers)\n",
    "valid_dl = DataLoader(valid_ds, bs=H.bs,                               num_workers=H.workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mask,x_cat, x_cont, x_tags, x_tagw, y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)\n",
    "torch.set_printoptions(precision=4, linewidth=200, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2928, -0.3581, -0.1834,  ..., -0.0769,  0.0000,  0.0000],\n",
       "        [-0.2928, -0.3581, -0.1834,  ..., -0.0765, -0.0427, -0.5176],\n",
       "        [-0.2928, -0.3581, -0.1834,  ..., -0.0760, -0.0427, -0.4131],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cont[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([48, 500, 11]),\n",
       " torch.Size([48, 500, 23]),\n",
       " torch.Size([48, 500, 6]),\n",
       " torch.Size([48, 500, 6]),\n",
       " torch.Size([48, 500, 2]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cat.shape, x_cont.shape, x_tags.shape, x_tagw.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x_cat.isnan().any() == False\n",
    "assert x_cont.isnan().any() == False\n",
    "assert x_tags.isnan().any() == False\n",
    "assert x_tagw.isnan().any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x_cat.shape == (H.bs, H.chunk_size*H.n_chunks, len(meta.cat_names))\n",
    "assert x_cont.shape == (H.bs, H.chunk_size*H.n_chunks, len(meta.cont_names))\n",
    "assert x_tags.shape == x_tagw.shape == (H.bs, H.chunk_size*H.n_chunks, 6)\n",
    "assert y.shape == (H.bs, H.chunk_size*H.n_chunks, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(pred, targ):\n",
    "    pred = torch.softmax(pred, dim=2)\n",
    "    pred = pred[:,:,1:2] # prediction for True\n",
    "    idx = targ != -1\n",
    "    pred = pred[idx]\n",
    "    targ = targ[idx]\n",
    "    pred, targ = flatten_check(pred, targ)\n",
    "    if len(targ.unique()) == 2:\n",
    "        return roc_auc_score(targ.cpu().numpy(), pred.cpu().numpy())\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss if H.loss=='ce' else globals()[H.loss]\n",
    "loss    = loss_fn(ignore_index=-1)\n",
    "loss_nr = loss_fn(ignore_index=-1, reduction='none')\n",
    "\n",
    "def loss_func(pred, targ, shuffle=None, lam=None):\n",
    "    b, s, l = pred.shape\n",
    "    if shuffle is not None:\n",
    "        targ_shuffled = targ[shuffle].view(b*s)\n",
    "    pred = pred.view(b*s, l)\n",
    "    targ = targ.view(b*s)\n",
    "\n",
    "    if shuffle is not None:\n",
    "        l0 = loss_nr(pred, targ).view(b, s)\n",
    "        l1 = loss_nr(pred, targ_shuffled).view(b, s)\n",
    "        return torch.lerp(l0, l1, lam.view(lam.shape[0], 1)).mean()\n",
    "    else:\n",
    "        #print(targ.unique()) # CUDA assert error if any index here is bigger than dimension l (labels) of pred\n",
    "        return loss(pred, targ)\n",
    "    \n",
    "def ua_loss_func(pred, targ, shuffle=None, lam=None):\n",
    "    loss_fn = loss_func\n",
    "    l = loss_fn(pred[...,:2],targ[...,:1],shuffle,lam) \n",
    "    if H.wua and targ.shape[-1]>1: l += H.wua * loss_fn(pred[...,2:],targ[...,1:],shuffle,lam)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noexport\n",
    "_p = torch.zeros([32, 127, 6])\n",
    "_t = torch.empty ([32, 127,2]).type(torch.long)\n",
    "_t[...,0] = torch.randint(2,_t.shape[:2])\n",
    "_t[...,1] = torch.randint(4,_t.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#noexport\n",
    "roc_auc(_p[...,:2], _t[...,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#noexport\n",
    "loss_func(_p[...,:2], _t[...,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#noexport\n",
    "ua_loss_func(_p, _t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBMetric(Metric):\n",
    "    def __init__(self, loss_func, name):\n",
    "        self.loss_func = loss_func\n",
    "        self.nam = name\n",
    "        \n",
    "    def reset(self):\n",
    "        self.targs, self.preds = [], []\n",
    "        \n",
    "    def accumulate(self, learn):\n",
    "        self.preds.append(learn.to_detach(learn.pred[...,:2]))\n",
    "        self.targs.append(learn.to_detach(learn.y[...,:1]))\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        if len(self.preds) == 0: return\n",
    "        preds = torch.cat(self.preds)\n",
    "        targs = torch.cat(self.targs)\n",
    "        r = self.loss_func(preds, targs)\n",
    "        return r\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.nam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#noexport\n",
    "lam = Beta(0.5, 0.5).sample((10000,))\n",
    "lam = torch.stack([lam, 1-lam], 1)\n",
    "lam = lam.max(1)[0].numpy()\n",
    "_ = plt.hist(lam, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMixUp(Callback):\n",
    "    run_after,run_valid = [Normalize],False\n",
    "    def __init__(self, alpha=0.4): \n",
    "        self.distrib = Beta(tensor(alpha), tensor(alpha))\n",
    "\n",
    "    def before_batch(self):\n",
    "        lam = self.distrib.sample((self.y.size(0),)).squeeze().to(self.y.device)\n",
    "        lam = torch.stack([lam, 1-lam], 1)\n",
    "        lam = lam.max(1)[0]\n",
    "        shuffle = torch.randperm(self.y.size(0)).to(self.y.device)\n",
    "        self.learn.xb = (*self.xb, shuffle, lam)\n",
    "        self.learn.yb = (*self.yb, shuffle, lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientClipping(Callback):\n",
    "    \"Gradient clipping during training.\"\n",
    "    def __init__(self, clip:float = 0.):\n",
    "        self.clip = clip\n",
    "\n",
    "    def after_backward(self, **kwargs):\n",
    "        \"Clip the gradient before the optimizer step.\"\n",
    "        if self.clip: nn.utils.clip_grad_norm_(self.learn.model.parameters(), self.clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TutorNet(nn.Module):\n",
    "    def __init__(self, emb_szs, tag_emb_szs, emb_do, n_cont, trf_dim, trf_enc, trf_dec, trf_heads, trf_do, trf_act):\n",
    "        super().__init__()\n",
    "        self.nhead,self.trf_dim = trf_heads, trf_dim\n",
    "        \n",
    "        tag_emb_szs =(tag_emb_szs[0]+1, trf_dim)\n",
    "\n",
    "        self.embeds    = nn.ModuleList([nn.Sequential(nn.Embedding(ni+1, nf, max_norm=1.),nn.Linear(nf, trf_dim)) \n",
    "                                        for ni, nf in emb_szs])\n",
    "        self.tagembeds = nn.EmbeddingBag(*tag_emb_szs, max_norm=1., mode='sum')\n",
    "        self.conts     = nn.Linear(n_cont, trf_dim)\n",
    "            \n",
    "        self.trafo = nn.Transformer(\n",
    "            d_model = trf_dim,\n",
    "            nhead = trf_heads,\n",
    "            num_encoder_layers = trf_enc,\n",
    "            num_decoder_layers = trf_dec,\n",
    "            dim_feedforward = trf_dim*4,\n",
    "            dropout = trf_do,\n",
    "            activation = trf_act,\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Linear(trf_dim, 6)\n",
    "        \n",
    "    def forward(self, x_mask, x_cat, x_cont, x_tags, x_tagw, shuffle=None, lam=None):\n",
    "        b, sl, catf, contf, tagsf = (*x_cat.shape, x_cont.shape[2], x_tags.shape[2])\n",
    "        \n",
    "        x_cat  += 1\n",
    "        x_tags += 1\n",
    "    \n",
    "        # compute masks\n",
    "        causal_mask  = torch.triu(torch.ones(1,sl, sl,dtype=torch.bool,device=x_cat.device), diagonal=1).expand(b,-1,-1)\n",
    "        x_tci   = x_cat[...,Cats.task_container_id]\n",
    "        x_tci_s = torch.zeros_like(x_tci)\n",
    "        x_tci_s[...,1:] = x_tci[...,:-1]\n",
    "        enc_container_aware_mask =  (x_tci.unsqueeze(-1) == x_tci_s.unsqueeze(-1).permute(0,2,1)) | causal_mask\n",
    "        dec_container_aware_mask = ~(x_tci.unsqueeze(-1) == x_tci.unsqueeze(-1).permute(0,2,1))   & causal_mask\n",
    "\n",
    "        padding_mask = x_mask \n",
    "                \n",
    "        # encoder x (shifted q & a)\n",
    "        enc_cat  = torch.zeros_like(x_cat)\n",
    "        enc_cont = torch.zeros_like(x_cont)\n",
    "        enc_tags = torch.zeros_like(x_tags)\n",
    "        enc_tagw = torch.zeros_like(x_tagw)\n",
    "        \n",
    "        enc_cat[:,1:]  = x_cat[:,:-1]\n",
    "        enc_cont[:,1:] = x_cont[:,:-1]\n",
    "        enc_tags[:,1:] = x_tags[:,:-1]\n",
    "        enc_tagw[:,1:] = x_tagw[:,:-1]\n",
    "        \n",
    "        # decoder x (nonshifted q)\n",
    "        dec_cat  = x_cat\n",
    "        dec_cont = x_cont\n",
    "        dec_tags = x_tags\n",
    "        dec_tagw = x_tagw\n",
    "\n",
    "        # hide correct answer and user answered correctly from decoder\n",
    "        dec_cat[...,Cats.answered_correctly] = 0\n",
    "        dec_cat[...,Cats.user_answer] = 0\n",
    "        dec_cat[...,Cats.qhe] = 0\n",
    "        dec_cont[...,Conts.qet] = 0\n",
    "        dec_cont[...,Conts.qet_log] = 0\n",
    "        \n",
    "        # print(enc_cont.shape)\n",
    "        enc_cat  =  enc_cat.view(b * sl, catf)   # b*sl, catf\n",
    "        enc_tags = enc_tags.view(b * sl, tagsf) # b*sl, tagsf\n",
    "        enc_tagw = enc_tagw.view(b * sl, tagsf) # b*sl, tagsf\n",
    "\n",
    "        dec_cat  =  dec_cat.view(b * sl, catf)   # b*sl, catf\n",
    "        dec_tags = dec_tags.view(b * sl, tagsf) # b*sl, tagsf\n",
    "        dec_tagw = dec_tagw.view(b * sl, tagsf) # b*sl, tagsf\n",
    "        \n",
    "        # embed categorical vars\n",
    "        enc = torch.mean(torch.stack([\n",
    "            *[ e(enc_cat[:,i]) for i, e in enumerate(self.embeds) ],\n",
    "            self.tagembeds(enc_tags, per_sample_weights=enc_tagw),\n",
    "            self.conts(enc_cont).view(-1,self.trf_dim)\n",
    "        ]),dim=0)\n",
    "        \n",
    "        dec = torch.mean(torch.stack([\n",
    "            *[ e(dec_cat[:,i]) for i, e in enumerate(self.embeds) ],\n",
    "            self.tagembeds(dec_tags, per_sample_weights=dec_tagw),\n",
    "            self.conts(dec_cont).view(-1,self.trf_dim)\n",
    "        ]),dim=0)\n",
    "        \n",
    "        enc = enc.view(b, sl, self.trf_dim)           # b, sl, sum of cat, cont and tag ftrs\n",
    "        dec = dec.view(b, sl, self.trf_dim)           # b, sl, sum of cat, cont and tag ftrs\n",
    "\n",
    "        if shuffle is not None:\n",
    "            enc = torch.lerp(enc, enc[shuffle], lam.view(lam.shape[0], 1, 1))\n",
    "            dec = torch.lerp(dec, dec[shuffle], lam.view(lam.shape[0], 1, 1))\n",
    "            padding_mask = None\n",
    "            enc_container_aware_mask = dec_container_aware_mask = causal_mask | causal_mask[shuffle]\n",
    "        \n",
    "        enc = enc.permute(1, 0, 2)          # sl, b, tf (torchformer input)\n",
    "        dec = dec.permute(1, 0, 2)          # sl, b, tf\n",
    "\n",
    "        expand_nheads = lambda t: t.unsqueeze(1).expand(t.shape[0],self.nhead,-1,-1).reshape(-1,*t.shape[-2:])\n",
    "        \n",
    "        o = self.trafo(\n",
    "            enc, \n",
    "            dec, \n",
    "            src_mask = expand_nheads(enc_container_aware_mask),\n",
    "            tgt_mask = expand_nheads(dec_container_aware_mask),\n",
    "            memory_mask = expand_nheads(enc_container_aware_mask),\n",
    "            src_key_padding_mask = padding_mask,\n",
    "            tgt_key_padding_mask = padding_mask,\n",
    "            memory_key_padding_mask = padding_mask,\n",
    "        )                                   # sl, b, tf\n",
    "        o = o.permute(1, 0, 2)              # b, sl, tf\n",
    "        o = self.mlp(o)                     # b, sl, of (of=2)\n",
    "        #print(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = list(zip(meta.n_emb.values(), meta.emb_dim.values()))\n",
    "tag_emb_szs = meta.tags_n_emb, meta.tags_emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TutorNet(emb_szs, tag_emb_szs, None, len(meta.cont_names), \n",
    "                 H.trf_dim, H.trf_enc, H.trf_dec, H.trf_heads, H.trf_do, H.trf_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-Fixup init\n",
    "\n",
    "1. Apply Xavier initialization for all parameters excluding input embeddings. Use Gaussian initialization $N(0,d^{-\\frac{1}{2}})$ for input embeddings where d is the embedding dimension.\n",
    "\n",
    "2. Scale $v_{d}$ and $w_{d}$ matrices in each decoder attention block, weight matrices in each decoder MLP block and input embeddings $x$ and $y$ in encoder and decoder by $(9N)^{−\\frac{1}{4}}$: [code](https://github.com/layer6ai-labs/T-Fixup/blob/f1fae213ce7b48829f81632d0c96bb039b7c450e/fairseq/modules/transformer_layer.py#L161), [code](https://github.com/layer6ai-labs/T-Fixup/blob/f1fae213ce7b48829f81632d0c96bb039b7c450e/fairseq/models/transformer.py#L378), [code](https://github.com/layer6ai-labs/T-Fixup/blob/f1fae213ce7b48829f81632d0c96bb039b7c450e/fairseq/models/transformer.py#L604)\n",
    "\n",
    "3. Scale $v_{e}$ and $w_{e}$ matrices in each encoder attention block and weight matrices in each encoder MLP block by $0.67N^{−\\frac{1}{4}}$: [code](https://github.com/layer6ai-labs/T-Fixup/blob/f1fae213ce7b48829f81632d0c96bb039b7c450e/fairseq/modules/transformer_layer.py#L36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_normal_(x, mean=0., std=1.):\n",
    "    \"Truncated normal initialization (approximation)\"\n",
    "    # From https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/12\n",
    "    return x.normal_().fmod_(2).mul_(std).add_(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if H.tfixup:\n",
    "    for n,p in model.named_parameters():\n",
    "        if re.match(r'.*bias$|.*bn\\.weight$|.*norm.*\\.weight',n): continue\n",
    "        gain = 1.\n",
    "        if re.match(r'.*decoder.*',n): \n",
    "            gain = (9*H.trf_dec)**(-1./4.)\n",
    "            if re.match(f'.*in_proj_weight$',n): gain *= (2**0.5)\n",
    "        elif re.match(r'.*encoder.*',n): \n",
    "            gain = 0.67*(H.trf_enc**(-1./4.))\n",
    "            if re.match(f'.*in_proj_weight$',n): gain *= (2**0.5)\n",
    "        if re.match(r'^embeds|^tagembeds', n): \n",
    "            trunc_normal_(p.data,std=(4.5*(H.trf_enc+H.trf_dec))**(-1./4.)*H.trf_dim**(-0.5))\n",
    "        else:                                  \n",
    "            nn.init.xavier_normal_(p,gain=gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if H.tfixup:\n",
    "    class MyModelPatcher(ModelPatcher):\n",
    "        def new_child_module(self, child_module_name, child_module, patch_info): return nn.Identity()\n",
    "    mp = MyModelPatcher()\n",
    "    mp.add_pattern(r\".*norm\\d?.*\",{})\n",
    "    mp.patch_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TutorNet(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Embedding(3, 1, max_norm=1.0)\n",
       "      (1): Linear(in_features=1, out_features=512, bias=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Embedding(5, 3, max_norm=1.0)\n",
       "      (1): Linear(in_features=3, out_features=512, bias=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Embedding(9767, 274, max_norm=1.0)\n",
       "      (1): Linear(in_features=274, out_features=512, bias=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Embedding(6, 4, max_norm=1.0)\n",
       "      (1): Linear(in_features=4, out_features=512, bias=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Embedding(420, 47, max_norm=1.0)\n",
       "      (1): Linear(in_features=47, out_features=512, bias=True)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Embedding(9, 5, max_norm=1.0)\n",
       "      (1): Linear(in_features=5, out_features=512, bias=True)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Embedding(4, 3, max_norm=1.0)\n",
       "      (1): Linear(in_features=3, out_features=512, bias=True)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Embedding(13525, 329, max_norm=1.0)\n",
       "      (1): Linear(in_features=329, out_features=512, bias=True)\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): Embedding(10002, 278, max_norm=1.0)\n",
       "      (1): Linear(in_features=278, out_features=512, bias=True)\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): Embedding(6, 4, max_norm=1.0)\n",
       "      (1): Linear(in_features=4, out_features=512, bias=True)\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (0): Embedding(7, 4, max_norm=1.0)\n",
       "      (1): Linear(in_features=4, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (tagembeds): EmbeddingBag(190, 512, max_norm=1.0, mode=sum)\n",
       "  (conts): Linear(in_features=23, out_features=512, bias=True)\n",
       "  (trafo): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): Identity()\n",
       "          (norm2): Identity()\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): Identity()\n",
       "          (norm2): Identity()\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): Identity()\n",
       "          (norm2): Identity()\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): Identity()\n",
       "          (norm2): Identity()\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): Identity()\n",
       "          (norm2): Identity()\n",
       "          (norm3): Identity()\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): Identity()\n",
       "          (norm2): Identity()\n",
       "          (norm3): Identity()\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): Identity()\n",
       "          (norm2): Identity()\n",
       "          (norm3): Identity()\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): Identity()\n",
       "          (norm2): Identity()\n",
       "          (norm3): Identity()\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): Identity()\n",
       "    )\n",
       "  )\n",
       "  (mlp): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#noexport\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dls.cuda()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates(Lamb)\n",
    "def ranger_lamb(p, lr, mom=0.95, wd=0.01, eps=1e-6, **kwargs):\n",
    "    return Lookahead(Lamb(p, lr=lr, mom=mom, wd=wd, eps=eps, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    loss_func=ua_loss_func,\n",
    "    opt_func=partial(globals()[H.opt],**H.opt_kwargs),\n",
    "    moms = H.moms,\n",
    "    metrics=[\n",
    "        LBMetric(loss_func, 'acc_valid_loss'),\n",
    "        LBMetric(roc_auc, 'acc_roc_auc'),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_fp16 = getattr(learn,H.fp16,None)\n",
    "if f_fp16: f_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank0_only(func, *args, **kwargs):\n",
    "    \"Execute `func` in the Rank-0 process first, then in other ranks in parallel.\"\n",
    "    if args or kwargs: func = partial(func, *args, **kwargs)\n",
    "    dummy_l = Learner(DataLoaders(device='cpu'), nn.Linear(1,1), loss_func=lambda: 0)\n",
    "    res = None\n",
    "    with dummy_l.distrib_ctx():\n",
    "        if not rank_distrib(): res = func()\n",
    "        distrib_barrier()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def load(learn:Learner,fn,with_opt=False):\n",
    "    def __inner(learn:Learner,fn,with_opt=False):\n",
    "        m_dict = torch.load(f\"{(Path(learn.model_dir) / fn)}.pth\")#['model']\n",
    "        ks = []\n",
    "        for attempts in range(2):\n",
    "            try:\n",
    "                res = learn.model.load_state_dict(m_dict,strict=False)\n",
    "                print(f\"Loaded {fn} ignoring: {' '.join(ks)} and {res}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                for k in [m[1] for m in [re.match(r\"^.*mismatch for ([\\w\\.]+):\",l) for l in str(e).split(\"\\n\")] if m is not None]:\n",
    "                    m_dict.pop(k,None)\n",
    "                    ks.append(k)\n",
    "        return learn\n",
    "    return rank0_only(__inner, learn, fn, with_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if H.load:\n",
    "    learn.load(H.load, with_opt=False)\n",
    "    print(f\"Loaded: {H.load}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if H.clip: \n",
    "    learn.add_cb(GradientClipping(H.clip))\n",
    "    print('clip on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if H.local_rank is not None: \n",
    "    learn.to_distributed(H.local_rank)\n",
    "    print('local_rank on')\n",
    "if H.mixup: \n",
    "    learn.add_cb(MyMixUp(0.5))\n",
    "    print('mixup on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "if H.validate:\n",
    "    res = learn.validate()\n",
    "    print(f\"CV: {res[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TutorNet (Input shape: 48 x 500)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     48 x 1              \n",
       "Embedding                                 3          True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 512            \n",
       "Linear                                    1024       True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 3              \n",
       "Embedding                                 15         True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 512            \n",
       "Linear                                    2048       True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 274            \n",
       "Embedding                                 2676158    True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 512            \n",
       "Linear                                    140800     True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 4              \n",
       "Embedding                                 24         True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 512            \n",
       "Linear                                    2560       True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 47             \n",
       "Embedding                                 19740      True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 512            \n",
       "Linear                                    24576      True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 5              \n",
       "Embedding                                 45         True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 512            \n",
       "Linear                                    3072       True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 3              \n",
       "Embedding                                 12         True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 512            \n",
       "Linear                                    2048       True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 329            \n",
       "Embedding                                 4449725    True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 512            \n",
       "Linear                                    168960     True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 278            \n",
       "Embedding                                 2780556    True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 512            \n",
       "Linear                                    142848     True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 4              \n",
       "Embedding                                 24         True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 512            \n",
       "Linear                                    2560       True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 4              \n",
       "Embedding                                 28         True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 512            \n",
       "Linear                                    2560       True      \n",
       "EmbeddingBag                              97280      True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 500 x 512      \n",
       "Linear                                    12288      True      \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 512        \n",
       "Linear                                    1049088    True      \n",
       "Identity                                                       \n",
       "Identity                                                       \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 512        \n",
       "Linear                                    1049088    True      \n",
       "Identity                                                       \n",
       "Identity                                                       \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 512        \n",
       "Linear                                    1049088    True      \n",
       "Identity                                                       \n",
       "Identity                                                       \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 512        \n",
       "Linear                                    1049088    True      \n",
       "Identity                                                       \n",
       "Identity                                                       \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 512        \n",
       "Linear                                    1049088    True      \n",
       "Identity                                                       \n",
       "Identity                                                       \n",
       "Identity                                                       \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 512        \n",
       "Linear                                    1049088    True      \n",
       "Identity                                                       \n",
       "Identity                                                       \n",
       "Identity                                                       \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 512        \n",
       "Linear                                    1049088    True      \n",
       "Identity                                                       \n",
       "Identity                                                       \n",
       "Identity                                                       \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 2048       \n",
       "Linear                                    1050624    True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     48 x 1 x 512        \n",
       "Linear                                    1049088    True      \n",
       "Identity                                                       \n",
       "Identity                                                       \n",
       "Identity                                                       \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "Dropout                                                        \n",
       "Identity                                                       \n",
       "____________________________________________________________________________\n",
       "                     48 x 500 x 6        \n",
       "Linear                                    3078       True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 27,329,728\n",
       "Total trainable params: 27,329,728\n",
       "Total non-trainable params: 0\n",
       "\n",
       "Optimizer used: functools.partial(<function ranger_lamb at 0x7f4d8228d280>)\n",
       "Loss function: <function ua_loss_func at 0x7f4deb1533a0>\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - MixedPrecision\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#noexport\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noexport\n",
    "#learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noexport\n",
    "#learn.recorder.plot_lr_find(skip_end=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#short_cb = learn.add_cb(ShortEpochCallback(pct=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f4d822c3d60>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.add_cb(SaveModelCallback(monitor='acc_roc_auc', comp=np.greater, fname=f'best{H.model}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_flat_cos 5 0.003 {'pct_start': 0.5, 'div_final': 100.0}\n"
     ]
    }
   ],
   "source": [
    "print(H.fit, H.epochs, H.lr, H.fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.966696</td>\n",
       "      <td>14.766358</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12.346977</td>\n",
       "      <td>4.096241</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.069063</td>\n",
       "      <td>0.411127</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.452080</td>\n",
       "      <td>0.022483</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.890170</td>\n",
       "      <td>0.013391</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#noexport\n",
    "syn_learn = synth_learner()\n",
    "getattr(syn_learn,H.fit)(H.epochs, H.lr,**H.fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#noexport\n",
    "syn_learn.recorder.plot_sched()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- model: 210105\n",
       "- data: 210101b\n",
       "- load: None\n",
       "- validate: False\n",
       "- chunk_size: 500\n",
       "- n_chunks: 1\n",
       "- bs: 48\n",
       "- workers: 8\n",
       "- valid_pct: 0.025\n",
       "- trf_dim: 512\n",
       "- trf_enc: 4\n",
       "- trf_dec: 4\n",
       "- trf_heads: 4\n",
       "- trf_do: 0.1\n",
       "- trf_act: gelu\n",
       "- lr: 0.003\n",
       "- clip: 0.0\n",
       "- moms: (0.95, 0.85, 0.95)\n",
       "- epochs: 5\n",
       "- tfixup: True\n",
       "- mixup: False\n",
       "- opt: ranger_lamb\n",
       "- opt_kwargs: \n",
       "\n",
       "- fit: fit_flat_cos\n",
       "- fit_kwargs: \n",
       "  - pct_start: 0.5\n",
       "  - div_final: 100.0\n",
       "- fp16: to_fp16\n",
       "- loss: ce\n",
       "- wua: 0.0\n",
       "- pad: r\n",
       "- local_rank: None"
      ],
      "text/plain": [
       "- model: 210105\n",
       "- data: 210101b\n",
       "- load: None\n",
       "- validate: False\n",
       "- chunk_size: 500\n",
       "- n_chunks: 1\n",
       "- bs: 48\n",
       "- workers: 8\n",
       "- valid_pct: 0.025\n",
       "- trf_dim: 512\n",
       "- trf_enc: 4\n",
       "- trf_dec: 4\n",
       "- trf_heads: 4\n",
       "- trf_do: 0.1\n",
       "- trf_act: gelu\n",
       "- lr: 0.003\n",
       "- clip: 0.0\n",
       "- moms: (0.95, 0.85, 0.95)\n",
       "- epochs: 5\n",
       "- tfixup: True\n",
       "- mixup: False\n",
       "- opt: ranger_lamb\n",
       "- opt_kwargs: \n",
       "\n",
       "- fit: fit_flat_cos\n",
       "- fit_kwargs: \n",
       "  - pct_start: 0.5\n",
       "  - div_final: 100.0\n",
       "- fp16: to_fp16\n",
       "- loss: ce\n",
       "- wua: 0.0\n",
       "- pad: r\n",
       "- local_rank: None"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.fit_flat_cos(H.epochs, H.lr,**H.fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>acc_valid_loss</th>\n",
       "      <th>acc_roc_auc</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.516579</td>\n",
       "      <td>0.515066</td>\n",
       "      <td>0.510675</td>\n",
       "      <td>0.793318</td>\n",
       "      <td>1:14:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.510655</td>\n",
       "      <td>0.510763</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.797913</td>\n",
       "      <td>1:14:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.508685</td>\n",
       "      <td>0.506038</td>\n",
       "      <td>0.501583</td>\n",
       "      <td>0.802250</td>\n",
       "      <td>1:14:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.501284</td>\n",
       "      <td>0.501635</td>\n",
       "      <td>0.497102</td>\n",
       "      <td>0.806428</td>\n",
       "      <td>1:15:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.498384</td>\n",
       "      <td>0.499137</td>\n",
       "      <td>0.494578</td>\n",
       "      <td>0.808618</td>\n",
       "      <td>1:14:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with acc_roc_auc value: 0.7933179432288439.\n",
      "Better model found at epoch 1 with acc_roc_auc value: 0.7979130787255149.\n",
      "Better model found at epoch 2 with acc_roc_auc value: 0.8022501124717482.\n",
      "Better model found at epoch 3 with acc_roc_auc value: 0.8064278025877302.\n",
      "Better model found at epoch 4 with acc_roc_auc value: 0.8086181047023688.\n",
      "Loaded best210105 ignoring:  and <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fitting {H.local_rank}\")\n",
    "getattr(learn,H.fit)(H.epochs, H.lr,**H.fit_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(#4) [0.5165794491767883,0.5150657296180725,0.5106747150421143,0.7933179432288439],\n",
       " (#4) [0.5106547474861145,0.5107629299163818,0.5064940452575684,0.7979130787255149],\n",
       " (#4) [0.5086852312088013,0.5060381889343262,0.5015827417373657,0.8022501124717482],\n",
       " (#4) [0.5012843012809753,0.5016353130340576,0.49710196256637573,0.8064278025877302],\n",
       " (#4) [0.4983840584754944,0.4991369843482971,0.4945776164531708,0.8086181047023688]]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#noexport\n",
    "learn.recorder.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#noexport\n",
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - PyTorch",
   "language": "python",
   "name": "azureml_py38_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
