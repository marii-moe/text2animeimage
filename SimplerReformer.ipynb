{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b3d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from fastai.basics import *\n",
    "from fastai.text.all import *\n",
    "from transformers import ReformerModelWithLMHead, ReformerTokenizerFast\n",
    "from fastai.callback.wandb import *\n",
    "#import wandb\n",
    "import torch\n",
    "from reformer_pytorch import Reformer\n",
    "from torch.utils.checkpoint import get_device_states\n",
    "TOKEN_SELF_ATTN_VALUE = -5e4 \n",
    "from local_attention import LocalAttention\n",
    "from functools import partial, reduce, wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reformer_pytorch import LSHSelfAttention\n",
    "from reformer_pytorch.reversible import ReversibleSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ae3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81162da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2265, -0.4902,  0.7183,  ..., -0.1998,  1.0268,  1.6641],\n",
      "         [-0.1284,  0.0688,  0.2674,  ...,  0.8180, -1.5623,  1.0299],\n",
      "         [ 0.9158,  0.6591, -1.8887,  ...,  0.4773, -0.2201,  1.6994],\n",
      "         ...,\n",
      "         [-1.3225,  1.1408, -0.4832,  ..., -0.0524,  0.6005,  1.3357],\n",
      "         [-1.1027,  0.1178, -0.5195,  ...,  0.4283,  0.2834, -0.2728],\n",
      "         [-0.1449, -3.3321, -1.4543,  ..., -0.5748,  1.1886, -0.0275]]],\n",
      "       device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "with no_random():\n",
    "    model = Reformer(\n",
    "        dim = 512,\n",
    "        depth = 12,\n",
    "        heads = 4,\n",
    "        lsh_dropout = 0.1\n",
    "    ).cuda()\n",
    "\n",
    "    x = torch.randn(1, 8192, 512).cuda()\n",
    "    print(model(x)) # (1, 8192, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de15213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  30,   28,   83,  ...,  934,  933,  916],\n",
       "        [   3,   13,   18,  ...,  942,  980,  922],\n",
       "        [  65,  101,  105,  ...,  913,  977,  930],\n",
       "        [  56,   10,   15,  ..., 1019,  901,  962]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len=8192\n",
    "lsh_attn=model.layers.blocks[0].f.net.fn.lsh_attn\n",
    "lsh_attn.hash_vectors(seq_len // lsh_attn.bucket_size,torch.randn([4, 8192, 128]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b85f58",
   "metadata": {},
   "source": [
    "#### Understanding `lsh_attn.hash_vectors`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b2abe",
   "metadata": {},
   "source": [
    "We start off by defining the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c725baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def hash_vectors(self, n_buckets, vecs)\n",
    "vecs=torch.randn([4, 8192, 128]) #[bs,seq_len,features]\n",
    "n_buckets=seq_len // lsh_attn.bucket_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e95ec2",
   "metadata": {},
   "source": [
    "We then set a few variables for easy use and validate `n_buckets`. `n_buckets` must be divisible by 2 as we are going to negate the vector \"scores\" latter, for the other half of the buckets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ad3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = vecs.shape[0]\n",
    "device = vecs.device\n",
    "\n",
    "# See https://arxiv.org/pdf/1509.02897.pdf\n",
    "# We sample a different random rotation for each round of hashing to\n",
    "# decrease the probability of hash misses.\n",
    "assert n_buckets % 2 == 0 #we need positive + negative buckets, so must be multiple of 2\n",
    "\n",
    "rot_size = n_buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8e7b7",
   "metadata": {},
   "source": [
    "We define the shape of the rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f05def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 8, 64)\n"
     ]
    }
   ],
   "source": [
    "rotations_shape = (\n",
    "     1, #bs placeholder\n",
    "    vecs.shape[-1], #features\n",
    "    lsh_attn.n_hashes, \n",
    "    rot_size // 2) #same as n_buckets//2\n",
    "print(rotations_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf36b0b9",
   "metadata": {},
   "source": [
    "We now generate the random rotations. `expand` copies so that they are the same for each item. \n",
    "\n",
    "These are applied in a similar way to a matrix multiply :) \n",
    "\n",
    "Note: In order to guarantee reproducibility we use no_random here due to random number generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2847a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with no_random():\n",
    "    random_rotations = torch.randn(rotations_shape, dtype=vecs.dtype, device=device).expand(batch_size, -1, -1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df53f039",
   "metadata": {},
   "source": [
    "Einsum is a way to explain matrix multiples in a very concise way, the main thing to notice is that f,features, is what disappears. So we get a \"score\" for all the for each compbination of 'bhti'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e2dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapes\n",
    "# b = bs\n",
    "# t = seq_len\n",
    "# i = n_buckets//2\n",
    "# h = n_hashes\n",
    "# f = features\n",
    "# features f is what is removed here, we end up with a \"score\" for each n_hash,seq_len,bucket\n",
    "rotated_vecs = torch.einsum('btf,bfhi->bhti', vecs, random_rotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b70ec4",
   "metadata": {},
   "source": [
    "##### Begin Einsum explanation: If you are already familiar with einsum, please skip this explanation!!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9084f1f5",
   "metadata": {},
   "source": [
    "This is the shape we want in the end: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48840ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8192, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotated_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300158f8",
   "metadata": {},
   "source": [
    "This is the shapes we currently have, notice `random_rotations` has too many deminsions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b575d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8192, 128]), torch.Size([4, 128, 8, 64]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape,random_rotations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8218b944",
   "metadata": {},
   "source": [
    "So we flatten it! They are now compatible with a matrix multiply. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf01a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_rotations.flatten(start_dim=-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5db117e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8192, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vecs@random_rotations.flatten(start_dim=-2)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f539a86",
   "metadata": {},
   "source": [
    "Ugh! Now we need to `unflatten` 512 :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546278d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8192, 8, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((vecs@random_rotations.flatten(start_dim=-2)).unflatten(-1,(8, 64))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2ca17",
   "metadata": {},
   "source": [
    "Nooooo!!!! We still don't match the shape of `rotated_vecs` so we have to transpose T.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8595d1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8192, 64])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vecs@random_rotations.flatten(start_dim=-2)).unflatten(-1,(8, 64)).transpose(1,2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93382cff",
   "metadata": {},
   "source": [
    "Lets check to see that it all worked: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d661373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((vecs@random_rotations.flatten(start_dim=-2)).unflatten(-1,(8, 64)).transpose(1,2)==rotated_vecs).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311bbe51",
   "metadata": {},
   "source": [
    "But Einsum is so much neater. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c48ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.einsum('btf,bfhi->bhti', vecs, random_rotations)==rotated_vecs).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39fa471",
   "metadata": {},
   "source": [
    "##### End Einsum explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f70ac",
   "metadata": {},
   "source": [
    "Lets take a look at `rotated_vecs` to remind us where we are at: [n_hash,seq_len,bucket]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6fbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 8192, 64]),\n",
       " tensor([[[-22.9653, -15.4491],\n",
       "          [  0.5603,  -0.2839]],\n",
       " \n",
       "         [[  5.3804,  -2.2699],\n",
       "          [ -4.3336,   0.3952]]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotated_vecs.shape,rotated_vecs[0,:2,:2,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c7199",
   "metadata": {},
   "source": [
    "We now negate the score for each bucket, large negative scores will become large positive scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_vecs = torch.cat([rotated_vecs, -rotated_vecs], dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded5691e",
   "metadata": {},
   "source": [
    "We now take the argmax, to get the bucket for each bs,n_hash,seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081fec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = torch.argmax(rotated_vecs, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c7a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 8192]),\n",
       " tensor([[47, 86],\n",
       "         [36, 61]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets.shape,buckets[0,:2,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2296113",
   "metadata": {},
   "source": [
    "Problem!!!! For each n_hash we do not want overlap in bucket numbers, so lets add appropriate offsets to each `n_hashes` dim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bb705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offsets = torch.arange(lsh_attn.n_hashes, device=device)\n",
    "offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3369a46",
   "metadata": {},
   "source": [
    "Each hash gets its own range of buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e70c01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 128, 256, 384, 512, 640, 768, 896]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offsets = torch.reshape(offsets * n_buckets, (1, -1, 1)) \n",
    "offsets[...,0] #just for display reasons, the last dim has 1 value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4237383d",
   "metadata": {},
   "source": [
    "We now add the offsets to their associated n_hashes values, and flatten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e97c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8192])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets.shape #dim 1(8) is n_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6249e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 65536])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = torch.reshape(buckets + offsets, (batch_size, -1,))\n",
    "buckets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3134e8e6",
   "metadata": {},
   "source": [
    "Check that we are correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6c9789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with no_random():\n",
    "    check = lsh_attn.hash_vectors(n_buckets,vecs)\n",
    "(buckets == check).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9704ce7",
   "metadata": {},
   "source": [
    "#### Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562509f9",
   "metadata": {},
   "source": [
    "After hashing we can order by the hash and then chunk, and then attend to vectors in this or the previous chunk, so we attend to a maximum of 2*chunksize. Not going to go indepth on this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0462077c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunked: {'type': <class 'tuple'>, '0shape': torch.Size([1, 8192, 8]), 'len': 64}\n",
      "x.shape: torch.Size([1, 8192, 512])\n"
     ]
    }
   ],
   "source": [
    " with torch.no_grad():\n",
    "    info={}\n",
    "    chunked=torch.chunk(x,64,dim=-1)\n",
    "    info['type']=type(chunked)\n",
    "    info['0shape']=chunked[0].shape\n",
    "    info['len']=len(chunked)\n",
    "    print('chunked:',info)\n",
    "    print('x.shape:',x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1fa80",
   "metadata": {},
   "source": [
    "#### Reversible Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7abb495",
   "metadata": {},
   "source": [
    "Reversible Networks allows us to calculate the input to a layer on the backward pass without storing the activations, and without using gradient checkpointing. This does however require us to split x into x1 and x2, and y into y1 and y2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdded3",
   "metadata": {},
   "source": [
    "This is the `forward` pass. Please notice that:\n",
    "<ul>\n",
    "<li>x2 = y2 - self.g(y1, **g_args)\n",
    "<li>x1 = y1 - self.f(x2, **f_args)\n",
    "</ul>\n",
    "So we can get back x1, and x2 given f,g,y1,and y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a44028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:1')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ=torch.ones(x.shape[:-1],dtype=int).cuda()\n",
    "targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62d8c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with no_random():\n",
    "    x = torch.randn(1, 8192, 512).cuda()\n",
    "    f=nn.Linear(256,256).cuda() #doesn't matter too much here\n",
    "    g=nn.Linear(256,256).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0633fc",
   "metadata": {},
   "source": [
    "This is what the forward looks like, lets just do two :) (with same weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbdcc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x):\n",
    "    x1, x2 = torch.chunk(x, 2, dim=2)\n",
    "    y1, y2 = None, None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y1 = x1 + f(x2)\n",
    "        y2 = x2 + g(y1)\n",
    "\n",
    "    return torch.cat([y1, y2], dim=2)\n",
    "y=forward_pass(x)\n",
    "y=forward_pass(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76119943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8192, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b167e38",
   "metadata": {},
   "source": [
    "To keep this simple I am going to run this through the loss function now, this would be where you would add your regular classification or LM head. We transpose as crossentropy expects the second deminsion to be the label deminsion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce31720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.7459, device='cuda:1')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.cross_entropy(y.transpose(-1,-2),targ)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6791f0f",
   "metadata": {},
   "source": [
    "Since we are doing this super by hand, we calculate the gradient now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f8f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_grad(y,targ):\n",
    "    with torch.no_grad():\n",
    "        return (F.softmax(y,dim=2)-F.one_hot(targ,num_classes=y.shape[-1]))/y.shape[0]/y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy=cross_entropy_grad(y,targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6424670b",
   "metadata": {},
   "source": [
    "Next is the `backward_pass`. The full function is below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b26bed",
   "metadata": {},
   "source": [
    "We start by setting up our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09fda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method head\n",
    "#def backward_pass(self, y, dy, f_args = {}, g_args = {}):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_y(y,dy):\n",
    "    y1, y2 = torch.chunk(y, 2, dim=2)\n",
    "    dy1, dy2 = torch.chunk(dy, 2, dim=2)\n",
    "    return y1,y2,dy1,dy2\n",
    "y1,y2,dy1,dy2=split_y(y,dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0089a803",
   "metadata": {},
   "source": [
    "We have `g`,`y1` and `dy2`, so we cab calculate the gradients for `g(y1)` because `y2= g(y1)+x2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323249a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_g_grad(g,y1,dy2):\n",
    "    with torch.enable_grad():\n",
    "        y1.requires_grad = True\n",
    "        gy1 = g(y1)\n",
    "        torch.autograd.backward(gy1, dy2)\n",
    "    return gy1\n",
    "gy1=update_g_grad(g,y1,dy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e03a71",
   "metadata": {},
   "source": [
    "Next we can calculate `x2`. `dx1` We can calculate `dx1` because we ran `torch.autograd.backward` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getx2dx1(y1,y2,dy1, gy1):\n",
    "    with torch.no_grad():\n",
    "        x2 = y2 - gy1\n",
    "        del y2, gy1\n",
    "\n",
    "        dx1 = dy1 + y1.grad\n",
    "        del dy1\n",
    "        y1.grad = None\n",
    "    return x2,dx1\n",
    "x2,dx1=getx2dx1(y1,y2,dy1, gy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3230cec9",
   "metadata": {},
   "source": [
    "We can run the backward pass for `f(x2)` now that we have `x2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c049105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_f_grad(f,x2):\n",
    "    with torch.enable_grad():\n",
    "        x2.requires_grad = True\n",
    "        fx2 = f(x2)\n",
    "        torch.autograd.backward(fx2, dx1, retain_graph=True)\n",
    "    return fx2\n",
    "fx2=update_f_grad(f,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d3be9",
   "metadata": {},
   "source": [
    "We can calculate the `x1` since `y1 = x1 + f(x2)`. `dx2` can be determined because of the above backward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4157e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xdx(fx2,x2,y1,dx1,dy2):\n",
    "    with torch.no_grad():\n",
    "        x1 = y1 - fx2\n",
    "        del y1, fx2\n",
    "\n",
    "        dx2 = dy2 + x2.grad\n",
    "        del dy2\n",
    "        x2.grad = None\n",
    "\n",
    "        x = torch.cat([x1, x2.detach()], dim=2)\n",
    "        dx = torch.cat([dx1, dx2], dim=2)\n",
    "        return x,dx\n",
    "x,dx=get_xdx(fx2,x2,y1,dx1,dy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8a88d",
   "metadata": {},
   "source": [
    "We have now completed one backward pass for a ReversibleBlock! Now lets do it for the second block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638fb60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y,dy=x,dx\n",
    "y1,y2,dy1,dy2=split_y(y,dy)\n",
    "gy1=update_g_grad(g,y1,dy2)\n",
    "x2,dx1=getx2dx1(y1,y2,dy1, gy1)\n",
    "fx2=update_f_grad(f,x2)\n",
    "x,dx=get_xdx(fx2,x2,y1,dx1,dy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2209ca6",
   "metadata": {},
   "source": [
    "Save the gradients so we can verify our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_grads=list(map(lambda p:p.grad.detach(),f.parameters()))\n",
    "g_grads=list(map(lambda p:p.grad.detach(),g.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reformer_pytorch.reversible import ReversibleBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00144aa7",
   "metadata": {},
   "source": [
    "Re-initialize variables for repeatability~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with no_random():\n",
    "    x = torch.randn(1, 8192, 512,requires_grad=True).cuda()\n",
    "    f=nn.Linear(256,256).cuda() #doesn't matter too much here\n",
    "    g=nn.Linear(256,256).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blocks=nn.Sequential(ReversibleBlock(f,g),ReversibleBlock(f,g))\n",
    "blocks=ReversibleSequence([(f,g),(f,g)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc2e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=blocks(x)\n",
    "y.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292d629a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.7459, device='cuda:1', grad_fn=<NllLoss2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = F.cross_entropy(y.transpose(-1,-2),targ)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f9bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991efc54",
   "metadata": {},
   "source": [
    "Test that reversible blocks are implemented correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c3fcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#works with lists of uneven tensors\n",
    "def is_close(a,b,eps=1e-5):\n",
    "    return all([((a_-b_)<1e-5).all() for a_,b_ in zip(a,b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf1ba3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_close(f_grads,list(map(lambda p:p.grad,f.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9facb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_close(g_grads,list(map(lambda p:p.grad,g.parameters())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
